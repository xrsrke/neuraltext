# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/12_model.ipynb.

# %% auto 0
__all__ = ['get_vocab', 'RNN']

# %% ../nbs/12_model.ipynb 4
from typing import Optional, Tuple

import torch
from torch import nn
import torch.nn.functional as F
from torchtyping import TensorType

# %% ../nbs/12_model.ipynb 5
def get_vocab():
    chars = ['a','b','c','d','e','f','g','h','i','j',
             'k','l','m','n','o','p','q','r','s','t',
             'u','v','w','x','y','z', '>',',',"'",'~','?'
    ]
    
    return {c: i for i, c in enumerate(chars)}
    

# %% ../nbs/12_model.ipynb 8
class RNN(nn.Module):
    """The Decoder Neural Signal."""
    def __init__(
        self,
        input_size: int = 192, # The firing rate
        hidden_size: int = 512,
        output_size: int = 31, # The number of vocabs
        slow_frequency: int = 100
    ):
        super().__init__()
        self.hidden_size = hidden_size
        self.slow_frequency = slow_frequency
        
        self.gru1 = nn.GRU(input_size, hidden_size)
        self.gru2 = nn.GRU(hidden_size, output_size)
        self.z_layer = nn.Linear(hidden_size, 1)
    
    def get_prob_next_character(
        self, x # The hidden state
    ) -> TensorType[1]: # The probability of the next character
        return F.sigmoid(self.z_layer(x))

    def forward(
        self,
        x: torch.Tensor, hidden: Optional[torch.Tensor] = None
    ) -> Tuple[
        torch.Tensor,
        torch.Tensor,
        TensorType[1]
    ]:
        """The forward pass."""
        gru1_out, hidden = self.gru1(x, hidden)
        gru2_out = self.gru2(gru1_out)[0][::self.slow_frequency]
        z_t = self.get_prob_next_character(hidden[0])
        return gru2_out, hidden, z_t
