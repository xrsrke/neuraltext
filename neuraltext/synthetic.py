# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/06_synthetic.ipynb.

# %% auto 0
__all__ = ['load_snippet', 'generate_random_sentence', 'SyntheticSentence']

# %% ../nbs/06_synthetic.ipynb 4
from typing import Tuple, Set
import random
import json

import torch
import torch.nn.functional as F
from torchtyping import TensorType

from .model import get_vocabs
from .utils import mat2dict

# %% ../nbs/06_synthetic.ipynb 7
def load_snippet(character: str, path: str = "./data/snippets/t5.2020.01.13_snippets.mat"):
    vocabs = get_vocabs().keys()
    assert character in vocabs, f"Vocab {character} not found"

    # TODO: don't hardcode >
    character = "greaterThan" if character == ">" else character
    snippets = mat2dict(path)
    return snippets[character]

# %% ../nbs/06_synthetic.ipynb 9
def generate_random_sentence(
    length: int, # The number of words in the sentence
    vocab_path: str = "./data/english/1000-english-words.json" # The path to the vocabulary
) -> str:
    with open(vocab_path, "r") as f:
        words = json.load(f)
    n_words = len(words)
    idxs = random.sample(range(n_words), length)
    text = " ".join([words[str(idx)] for idx in idxs])
    return text

# %% ../nbs/06_synthetic.ipynb 13
class SyntheticSentence:
    def __init__(self):
        self.vocabs = get_vocabs()

    def word2idx(self, x: str) -> int:
        return self.vocabs[x]
    
    def _extract_unique_characters(sentence: str) -> Set[str]:
        # Use a set comprehension to create a set of unique characters
        unique_chars = {char for char in sentence if char != ' '}
        # Return the set of unique characters as a sorted list
        return sorted(list(unique_chars))
    
    def _generate_character_probs(self, sentence: str) -> TensorType["seq_len", "n_vocabs"]:
        n_vocabs = len(self.vocabs)
        
        # TODO: don't hardcode
        fixed_sentence = sentence.replace(" ", ">")
        labels = [self.word2idx(x) for x in fixed_sentence]
        labels = torch.tensor(labels)
        
        one_hot = F.one_hot(labels, n_vocabs)
        return one_hot

    def _generate_character_signal(self, sentence) -> TensorType["seq_len"]:
        seq_len = len(sentence)
        x = torch.ones(seq_len)
        x[-1] = 0
        return x

    def generate(self, sentence: str) -> Tuple[
        TensorType["n_steps", "n_channels"], # neural data
        TensorType["seq_len", "n_vocabs"], # character probabilities
        TensorType["seq_len"] # character signals
    ]:
        neural_data = torch.tensor([])
        sentence = sentence.lower()  
        for character in sentence:
            character = ">" if character == " " else character        
            neural_template = load_snippet(character)[0][0]
            neural_template = torch.tensor(neural_template)
            neural_data = torch.cat((neural_data, neural_template), dim=0)
            probs = self._generate_character_probs(sentence)
            signals = self._generate_character_signal(sentence)
        
        return neural_data, probs, signals
